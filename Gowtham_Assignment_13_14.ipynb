{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Gowtham Assignment 13/14.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gowtham66866/Inkers/blob/master/Gowtham_Assignment_13_14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxk-nDoT5OpC",
        "colab_type": "text"
      },
      "source": [
        "Wrote Custom Momentum\n",
        "used CutOut "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDidBIt0Ccb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import time, math\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.eager as tfe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7LBLdFpCccC",
        "colab_type": "code",
        "outputId": "0adc637f-feaa-41b0-ba65-3b7df66c79b6",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Aug 24 17:45:44 2019       \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\r\n",
            "|-------------------------------+----------------------+----------------------+\r\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
            "|===============================+======================+======================|\r\n",
            "|   0  Tesla V100-SXM2...  On   | 00000000:00:04.0 Off |                    0 |\r\n",
            "| N/A   38C    P0    36W / 300W |     80MiB / 16130MiB |      0%      Default |\r\n",
            "+-------------------------------+----------------------+----------------------+\r\n",
            "                                                                               \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| Processes:                                                       GPU Memory |\r\n",
            "|  GPU       PID   Type   Process name                             Usage      |\r\n",
            "|=============================================================================|\r\n",
            "+-----------------------------------------------------------------------------+\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE0ToBu7CccE",
        "colab_type": "code",
        "outputId": "f3bc41c8-10bb-45d3-8daa-23687aaf10b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import multiprocessing\n",
        "\n",
        "multiprocessing.cpu_count()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n74bx88RCccI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq3lkBgXCccK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 512 #@param {type:\"integer\"}\n",
        "MOMENTUM = 0.9 #@param {type:\"number\"}\n",
        "LEARNING_RATE = 0.4 #@param {type:\"number\"}\n",
        "WEIGHT_DECAY = 5e-4 #@param {type:\"number\"}\n",
        "EPOCHS = 24 #@param {type:\"integer\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMhYgHUpCccM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_pytorch(shape, dtype=tf.float16, partition_info=None):\n",
        "  fan = np.prod(shape[:-1])\n",
        "  bound = 1 / math.sqrt(fan)\n",
        "  return tf.random.uniform(shape, minval=-bound, maxval=bound, dtype=dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPqet80BCccP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvBN(tf.keras.Model):\n",
        "  def __init__(self, c_out):\n",
        "    super().__init__()\n",
        "    self.conv = tf.keras.layers.Conv2D(filters=c_out, kernel_size=3, padding=\"SAME\", kernel_initializer=init_pytorch, use_bias=False)\n",
        "    self.bn = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.nn.relu(self.bn(self.conv(inputs)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGRQLXPvCccS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResBlk(tf.keras.Model):\n",
        "  def __init__(self, c_out, pool, res = False):\n",
        "    super().__init__()\n",
        "    self.conv_bn = ConvBN(c_out)\n",
        "    self.pool = pool\n",
        "    self.res = res\n",
        "    if self.res:\n",
        "      self.res1 = ConvBN(c_out)\n",
        "      self.res2 = ConvBN(c_out)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    h = self.pool(self.conv_bn(inputs))\n",
        "    if self.res:\n",
        "      h = h + self.res2(self.res1(h))\n",
        "    return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WJ2uywsCccW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DavidNet(tf.keras.Model):\n",
        "  def __init__(self, c=64, weight=0.2):\n",
        "    super().__init__()\n",
        "    pool = tf.keras.layers.MaxPooling2D()\n",
        "    self.init_conv_bn = ConvBN(c)\n",
        "    self.blk1 = ResBlk(c*2, pool, res = True)\n",
        "    self.blk2 = ResBlk(c*4, pool)\n",
        "    self.blk3 = ResBlk(c*8, pool, res = True)\n",
        "    self.pool = tf.keras.layers.GlobalMaxPool2D()\n",
        "    self.linear = tf.keras.layers.Dense(10, kernel_initializer=init_pytorch, use_bias=False)\n",
        "    self.weight = weight\n",
        "\n",
        "  def call(self, x, y):\n",
        "    h = self.pool(self.blk3(self.blk2(self.blk1(self.init_conv_bn(x)))))\n",
        "    h = self.linear(h) * self.weight\n",
        "    ce = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=h, labels=y)\n",
        "    loss = tf.reduce_sum(ce)\n",
        "    correct = tf.reduce_sum(tf.cast(tf.math.equal(tf.argmax(h, axis = 1), y), tf.float16))\n",
        "    return loss, correct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvYf2JHqCccZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a7e21a28-4474-4bed-cda8-42433012bfac"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "len_train, len_test = len(x_train), len(x_test)\n",
        "\n",
        "num_classes = 10\n",
        "y_train = y_train.astype('int64').reshape(len_train)\n",
        "y_test = y_test.astype('int64').reshape(len_test)\n",
        "\n",
        "train_mean = np.mean(x_train, axis=(0,1,2))\n",
        "train_std = np.std(x_train, axis=(0,1,2))\n",
        "\n",
        "normalize = lambda x: ((x - train_mean) / train_std).astype('float16') # todo: check here\n",
        "pad4 = lambda x: np.pad(x, [(0, 0), (4, 4), (4, 4), (0, 0)], mode='reflect')\n",
        "\n",
        "x_train = normalize(pad4(x_train))\n",
        "x_test = normalize(x_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRAKBTQqCccb",
        "colab_type": "text"
      },
      "source": [
        "# Cutout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiYLWw3kCccc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replace_slice(input_: tf.Tensor, replacement, begin) -> tf.Tensor:\n",
        "    inp_shape = tf.shape(input_)\n",
        "    size = tf.shape(replacement)\n",
        "    padding = tf.stack([begin, inp_shape - (begin + size)], axis=1)\n",
        "    replacement_pad = tf.pad(replacement, padding)\n",
        "    mask = tf.pad(tf.ones_like(replacement, dtype=tf.bool), padding)\n",
        "    return tf.where(mask, replacement_pad, input_)\n",
        "\n",
        "def cutout(x: tf.Tensor, h: int=8, w: int=8, c: int = 3) -> tf.Tensor:\n",
        "    shape = tf.shape(x)\n",
        "    x0 = tf.random.uniform([], 0, shape[0] + 1 - h, dtype=tf.int32)\n",
        "    y0 = tf.random.uniform([], 0, shape[1] + 1 - w, dtype=tf.int32)\n",
        "    \n",
        "    x = replace_slice(x, tf.zeros([h, w, c], dtype = tf.float16), [x0, y0, 0])\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r79tkdTICccf",
        "colab_type": "text"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuYhCEKGCccf",
        "colab_type": "text"
      },
      "source": [
        "# With\n",
        "lr_schedule = lambda t: np.interp([t], [0, (EPOCHS+1)//5, 21, EPOCHS], [0, LEARNING_RATE,0.021, 0])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0r6b70_2Cccg",
        "colab_type": "code",
        "outputId": "0b7eb5be-2802-4a50-9b8a-056781d6ac80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model = DavidNet()\n",
        "batches_per_epoch = len_train//BATCH_SIZE + 1\n",
        "lr_schedule = lambda t: np.interp([t], [0, (EPOCHS+1)//5, 21, EPOCHS], [0, LEARNING_RATE,0.021, 0])[0]\n",
        "global_step = tf.train.get_or_create_global_step()\n",
        "lr_func = lambda: lr_schedule(global_step/batches_per_epoch)/BATCH_SIZE\n",
        "data_aug = lambda x, y: (cutout(tf.image.random_flip_left_right(tf.random_crop(x, [32, 32, 3]))), y)\n",
        "\n",
        "\n",
        "t = time.time()\n",
        "test_set = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)\n",
        "\n",
        "mom_state = {}\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  train_loss = test_loss = train_acc = test_acc = 0.0\n",
        "  train_set = tf.data.Dataset.from_tensor_slices((x_train, y_train)).map(data_aug, num_parallel_calls=8).shuffle(len_train).batch(BATCH_SIZE).prefetch(1)\n",
        "\n",
        "  tf.keras.backend.set_learning_phase(1)\n",
        "  for (x, y) in train_set:\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss, correct = model(x, y)\n",
        "\n",
        "    var = model.trainable_variables\n",
        "    grads = tape.gradient(loss, var)\n",
        "    \n",
        "    global_step.assign_add(1)\n",
        "    lr = lr_func()\n",
        "\n",
        "    for g, v in zip(grads, var):\n",
        "      g += v * WEIGHT_DECAY * BATCH_SIZE\n",
        "      \n",
        "      if v not in mom_state:\n",
        "        state = tf.zeros_like(g)\n",
        "      else:\n",
        "        state = mom_state[v]\n",
        "        \n",
        "      state = state * MOMENTUM + g\n",
        "      g += state * MOMENTUM\n",
        "      v.assign_add(g * (-lr))\n",
        "      mom_state[v] = state\n",
        "\n",
        "\n",
        "    train_loss += loss.numpy()\n",
        "    train_acc += correct.numpy()\n",
        "\n",
        "  tf.keras.backend.set_learning_phase(0)\n",
        "  for (x, y) in test_set:\n",
        "    loss, correct = model(x, y)\n",
        "    test_loss += loss.numpy()\n",
        "    test_acc += correct.numpy()\n",
        "    \n",
        "  print('epoch:', epoch+1, 'lr:', lr_schedule(epoch+1), 'train loss:', train_loss / len_train, 'train acc:', train_acc / len_train, 'val loss:', test_loss / len_test, 'val acc:', test_acc / len_test, 'time:', time.time() - t)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-10-121d763a0a05>:7: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91u1ujS3nfcq",
        "colab_type": "text"
      },
      "source": [
        "Grid search for One cycle plicy LR finder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8HLM3wZnkCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# t = time.time()\n",
        "# test_set = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)\n",
        "# lr_list = np.linspace(0, 1, num=11);print(lr_list)\n",
        "# best_acc_lr_list = []\n",
        "\n",
        "# for lri in lr_list[1:]:\n",
        "#   t = time.time()\n",
        "#   reset_keras()\n",
        "#   model = DavidNet()\n",
        "#   batches_per_epoch = len_train//BATCH_SIZE + 1\n",
        "\n",
        "#   lr_schedule = lambda t: np.interp([t], [0, (EPOCHS+1)//5, EPOCHS], [lri/20, lri, 0])[0]\n",
        "#   global_step = tf.train.get_or_create_global_step()\n",
        "#   lr_func = lambda: lr_schedule(global_step/batches_per_epoch)/BATCH_SIZE\n",
        "#   opt = tf.train.MomentumOptimizer(lr_func, momentum=MOMENTUM, use_nesterov=True)\n",
        "#   data_aug = lambda x, y: (tf.image.random_flip_left_right(tf.random_crop(x, [32, 32, 3])), y)\n",
        "#   for epoch in range(5):\n",
        "#     train_loss = test_loss = train_acc = test_acc = 0.0\n",
        "#     train_set = tf.data.Dataset.from_tensor_slices((x_train, y_train)).map(data_aug1).shuffle(len_train).batch(BATCH_SIZE).prefetch(1)\n",
        "\n",
        "#     tf.keras.backend.set_learning_phase(1)\n",
        "#     for (x, y) in tqdm(train_set):\n",
        "#       with tf.GradientTape() as tape:\n",
        "#         loss, correct = model(x, y)\n",
        "\n",
        "#       var = model.trainable_variables\n",
        "#       grads = tape.gradient(loss, var)\n",
        "#       for g, v in zip(grads, var):\n",
        "#         g += v * WEIGHT_DECAY * BATCH_SIZE\n",
        "#       opt.apply_gradients(zip(grads, var), global_step=global_step)\n",
        "\n",
        "#       train_loss += loss.numpy()\n",
        "#       train_acc += correct.numpy()\n",
        "\n",
        "#     tf.keras.backend.set_learning_phase(0)\n",
        "#     for (x, y) in test_set:\n",
        "#       loss, correct = model(x, y)\n",
        "#       test_loss += loss.numpy()\n",
        "#       test_acc += correct.numpy()\n",
        "\n",
        "#     print('epoch:', epoch+1, 'lr:', lr_schedule(epoch+1), 'train loss:', train_loss / len_train, 'train acc:', train_acc / len_train, 'val loss:', test_loss / len_test, 'val acc:', test_acc / len_test, 'time:', time.time() - t)\n",
        "#   best_acc_lr_list.append(test_acc / len_test);print(\"test_acc\",test_acc / len_test)     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wJ7Km8ROSbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}